---
title: "Reproducing the whole-plant economics spectrum (summary & plan)"
author: "Kathi / Charlie / Luca"
date: 2025-10-31
format:
  revealjs:
    theme: moon
    transition: fade
    widescreen: true
---

## Summary — purpose

- Goal: integrate aboveground (GSPFF) and fine-root (RES) trait databases to build a joint whole-plant trait space and test coordination between leaves and roots.
- Key questions: how many axes describe global plant strategies; are leaf and root economics aligned; how do growth forms and biomes occupy trait space.

---

## Data (brief)

- Two primary sources:
  - GSPFF — ~46,000 species, 6 canonical aboveground traits (height, seed mass, leaf area, LMA, leaf N, etc.).
  - RES — ~1,500 species, 4 fine-root traits (SRL, D, RTD, RNC).
- Harmonized taxonomy; imputed missing traits (missForest + phylogenetic predictors).
- Complete-data core: 301 species; imputed full set: 1,218 species.

---

## Methods (brief)

- Multivariate ordination (PCA), varimax rotation for interpretability.
- Kernel-based trait probability densities (TPD) and null models (multivariate-normal) for hotspots and overlap.
- Procrustes tests, PERMANOVA, redundancy and dissimilarity metrics.
- Imputation: missForest (single run in the paper).

---

## Main results (paper, bullet form)

- Four orthogonal axes emerged: two aboveground (size, leaf economics) and two belowground (root tissue conservation, plant–fungal interaction gradient).
- Above- and belowground trait planes are partly coordinated but not tightly aligned.
- Woodiness explains much variation aboveground (~36.5%) but little in the fine-root plane (~0.4%).
- Different shapes of clustering (two hotspots aboveground, one hotspot belowground).

---

## Reproducibility plan — who does what (first ideas)

- Data & harmonization (Luca): verify raw data files in `Data/`, reproduce taxonomy harmonisation and imputation pipeline.
- Imputation & sensitivity (Alice): run multiple imputations (m ≈ 20) with missForest and propagate uncertainty through PCA/TPD.
- Ordination & null models (Charlie): reproduce PCA+varimax, TPD surfaces and null-model comparisons.
- Group-level stats & plots (Dana): reproduce PERMANOVA, redundancy analyses, and generate figures.
- Documentation & publishing (You): assemble runnable scripts, minimal example notebooks, and this Quarto presentation.

---

## Planned sensitivity tests (from critique)

1. Multiple imputation / parametric bootstrap to propagate uncertainty from missForest into PCA, TPD, PERMANOVA.
2. Field-only vs full-data pipeline: re-run entire PCA/TPD on field-only root records and compare with Procrustes/RV.
3. Consistent root-definition sensitivity: exclude species with mixed order/diameter definitions or run separate analyses per definition.
4. Bandwidth sensitivity in TPD (Hpi vs CV bandwidth vs scalar multiples).
5. Weighted PCA / reliability-weighted TPD (species weighting by number of studies / measurement quality).
6. NPP sensitivity: replace precipitation-based NPP proxy with gridded NPP products, and run partial regressions.
7. Bootstrap axis stability and phylogenetic signal analyses (Pagel's lambda / Blomberg's K) on axes.

---

## Minimal code example (R)

This slide shows a tiny R chunk that reads one of the data files and prints a quick summary.

```{r}
#| echo: true
library(here)
# read aboveground traits (tab-separated file in Data/)
path <- here::here("Data", "Above_traits.txt")
if (file.exists(path)) {
  d <- read.table(path, header = TRUE, sep = "\t", stringsAsFactors = FALSE)
  print(dim(d))
  print(head(d))
} else {
  cat("Data/Above_traits.txt not found in repository. Replace with the correct path.\n")
}
```

---

## Quick rendering & GitHub Pages publish instructions

1) Install Quarto (if not already):

- Windows: download from https://quarto.org and run the installer; or via choco if you use Chocolatey:

```powershell
choco install quarto
```

2) Render the reveal.js presentation locally (PowerShell):

```powershell
# render to a single HTML (default)
quarto render index.qmd --to revealjs

# recommended for GitHub Pages: render into a 'docs' folder so GitHub Pages can serve it from the repo
quarto render index.qmd --to revealjs --output-dir docs
```

3) Publish to GitHub Pages (simple manual approach):

```powershell
# create docs folder (if not exists), add the rendered output there, commit and push
git add docs
git commit -m "Add presentation for GitHub Pages"
git push origin main
```

- Then, on GitHub: Settings → Pages → Source → choose 'main' branch / 'docs' folder and save. The site will be available at https://<owner>.github.io/<repo>/

4) Automated approach (quarto publish):

```powershell
# this uses quarto's GitHub Pages helper (may require authentication)
quarto publish gh-pages --no-prompt
```

Notes:
- If you render to `docs/` the generated reveal.js assets (CSS/JS) will be placed there along with index.html; GitHub Pages will serve that folder.
- For reproducible builds on push, you can also add a GitHub Action that runs `quarto render` and deploys to Pages.

---

## Next steps / checklist

- [ ] Review slides and edit summary text if anything important is missing.
- [ ] Add a short runnable R script that reproduces the pipeline for one figure (e.g. PCA on 301 species).
- [ ] Create GitHub Action to render on push and deploy to Pages (optional; I can add it).

---

## References & notes

- Source notes used: `Notes/first-read-charlie.md` (summary) and `Notes/critique.md` (repro/tasks & sensitivity tests).
- Repository structure: place rendered files into `docs/` for GitHub Pages.


